{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e20da21",
   "metadata": {},
   "source": [
    "# Preprocessing:\n",
    "\n",
    "*Encode categorical data (e.g., 'Influencing Factor', 'Preferred Job') using one-hot encoding or MultiLabelBinarizer.\n",
    "\n",
    "\n",
    "\n",
    "*Normalize numerical data (e.g., CGPA, skill ratings) using StandardScaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dec4223b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>Critical Thinking</th>\n",
       "      <th>Problem Solving</th>\n",
       "      <th>Team Work</th>\n",
       "      <th>Communication Skill</th>\n",
       "      <th>Software Engineering Principal</th>\n",
       "      <th>Data Structure &amp; Algorithm</th>\n",
       "      <th>Database Management</th>\n",
       "      <th>Data Analysis skill</th>\n",
       "      <th>Web Developing Skill</th>\n",
       "      <th>...</th>\n",
       "      <th>Govt Job</th>\n",
       "      <th>Hardware Sector</th>\n",
       "      <th>ML/AI Engineer</th>\n",
       "      <th>Management</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Other</th>\n",
       "      <th>Researcher</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Teaching</th>\n",
       "      <th>UI/UX Designing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.84</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  Critical Thinking  Problem Solving  Team Work  Communication Skill  \\\n",
       "0  3.84                  2                3          3                    2   \n",
       "1  2.50                  1                1          1                    1   \n",
       "2  3.34                  2                2          2                    1   \n",
       "3  3.78                  2                3          2                    2   \n",
       "4  3.00                  2                3          3                    2   \n",
       "\n",
       "   Software Engineering Principal  Data Structure & Algorithm  \\\n",
       "0                               3                           3   \n",
       "1                               1                           1   \n",
       "2                               1                           2   \n",
       "3                               2                           2   \n",
       "4                               2                           2   \n",
       "\n",
       "   Database Management  Data Analysis skill  Web Developing Skill  ...  \\\n",
       "0                    2                    2                     3  ...   \n",
       "1                    1                    1                     2  ...   \n",
       "2                    2                    1                     2  ...   \n",
       "3                    2                    1                     2  ...   \n",
       "4                    3                    3                     3  ...   \n",
       "\n",
       "   Govt Job  Hardware Sector  ML/AI Engineer  Management  Networking  Other  \\\n",
       "0         0                0               0           0           0      0   \n",
       "1         0                0               0           0           0      0   \n",
       "2         0                0               0           0           0      0   \n",
       "3         0                0               0           0           0      0   \n",
       "4         0                0               0           0           0      0   \n",
       "\n",
       "   Researcher  Software Development  Teaching  UI/UX Designing  \n",
       "0           0                     1         1                0  \n",
       "1           0                     0         1                0  \n",
       "2           0                     1         0                0  \n",
       "3           0                     1         0                0  \n",
       "4           0                     1         0                0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert 'Prefer Job' and 'Influencing Factor' columns to string\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Splitting the multi-level categorical data into lists and strip extra spaces\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor'\n",
    "mlb = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb.fit_transform(df['Influencing Factor']), columns=mlb.classes_, index=df.index)\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Prefer Job'\n",
    "prefer_job_encoded = pd.DataFrame(mlb.fit_transform(df['Prefer Job']), columns=mlb.classes_, index=df.index)\n",
    "\n",
    "# Combining encoded features with the original dataframe\n",
    "df_encoded = pd.concat([df.drop(['Influencing Factor', 'Prefer Job'], axis=1), influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "df_encoded.head()\n",
    "#df_encoded.to_csv(\"preprocess_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93d687",
   "metadata": {},
   "source": [
    "# Feature Engineering:\n",
    "*Create new features by combining existing ones, such as average skill rating or the total number of projects/publications.\n",
    "\n",
    "\n",
    "\n",
    "*Use Principal Component Analysis (PCA) to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "939e4039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>Critical Thinking</th>\n",
       "      <th>Problem Solving</th>\n",
       "      <th>Team Work</th>\n",
       "      <th>Communication Skill</th>\n",
       "      <th>Software Engineering Principal</th>\n",
       "      <th>Data Structure &amp; Algorithm</th>\n",
       "      <th>Database Management</th>\n",
       "      <th>Data Analysis skill</th>\n",
       "      <th>Web Developing Skill</th>\n",
       "      <th>...</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Other</th>\n",
       "      <th>Researcher</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Teaching</th>\n",
       "      <th>UI/UX Designing</th>\n",
       "      <th>Average Skill Rating</th>\n",
       "      <th>Total Projects/Publications</th>\n",
       "      <th>Skill Diversity</th>\n",
       "      <th>ML_DA_Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.84</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.833684</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.438947</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725263</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  Critical Thinking  Problem Solving  Team Work  Communication Skill  \\\n",
       "0  3.84                  2                3          3                    2   \n",
       "1  2.50                  1                1          1                    1   \n",
       "2  3.34                  2                2          2                    1   \n",
       "3  3.78                  2                3          2                    2   \n",
       "4  3.00                  2                3          3                    2   \n",
       "\n",
       "   Software Engineering Principal  Data Structure & Algorithm  \\\n",
       "0                               3                           3   \n",
       "1                               1                           1   \n",
       "2                               1                           2   \n",
       "3                               2                           2   \n",
       "4                               2                           2   \n",
       "\n",
       "   Database Management  Data Analysis skill  Web Developing Skill  ...  \\\n",
       "0                    2                    2                     3  ...   \n",
       "1                    1                    1                     2  ...   \n",
       "2                    2                    1                     2  ...   \n",
       "3                    2                    1                     2  ...   \n",
       "4                    3                    3                     3  ...   \n",
       "\n",
       "   Networking  Other  Researcher  Software Development  Teaching  \\\n",
       "0           0      0           0                     1         1   \n",
       "1           0      0           0                     0         1   \n",
       "2           0      0           0                     1         0   \n",
       "3           0      0           0                     1         0   \n",
       "4           0      0           0                     1         0   \n",
       "\n",
       "   UI/UX Designing  Average Skill Rating  Total Projects/Publications  \\\n",
       "0                0              1.833684                            3   \n",
       "1                0              1.026316                            0   \n",
       "2                0              1.438947                            2   \n",
       "3                0              1.725263                            1   \n",
       "4                0              2.315789                            5   \n",
       "\n",
       "   Skill Diversity  ML_DA_Combination  \n",
       "0                6               True  \n",
       "1                1               True  \n",
       "2                1               True  \n",
       "3                2               True  \n",
       "4                9               True  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "skills_df = pd.read_csv('Skills_list.csv')\n",
    "skills = skills_df.iloc[:, 0].tolist()\n",
    "#skills\n",
    "\n",
    "df_encoded['Average Skill Rating'] = df_encoded[skills].mean(axis=1)\n",
    "\n",
    "# Example: Calculate total projects and publications\n",
    "df_encoded['Total Projects/Publications'] = df_encoded['project'] + df_encoded['publication']\n",
    "\n",
    "# Example: Count skills rated above a certain threshold\n",
    "threshold = 2  # Example threshold for skill rating\n",
    "df_encoded['Skill Diversity'] = (df_encoded[skills] > threshold).sum(axis=1)\n",
    "\n",
    "# Example: Create a feature for Machine Learning and Data Analysis combination\n",
    "df_encoded['ML_DA_Combination'] = (df_encoded['Machine Learning Skill'] > 0) & (df_encoded['Data Analysis skill'] > 0)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1d90c",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c60ec688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.19952798 0.07828794 0.05671501 0.0551711  0.04279966 0.04213798\n",
      " 0.03555744 0.03146324 0.02835046 0.02670578 0.02492058 0.02388963]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Assuming df_encoded and other variables are defined as in your previous code\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_encoded)  # Assuming 'Student ID' is not a feature\n",
    "\n",
    "# Initialize PCA with desired number of components\n",
    "n_components = 12  # Example: Reduce to 10 principal components\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit PCA and transform data\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Visualize cumulative explained variance ratio\n",
    "plt.plot(range(1, n_components+1), np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('PCA - Cumulative Explained Variance Ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc315cd8",
   "metadata": {},
   "source": [
    "# check every prefer job accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68deab01",
   "metadata": {},
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3068c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "columns_to_drop = ['Unnamed: 0', 'year', 'gender', 'university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string and apply MultiLabelBinarizer\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "# Drop original columns and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  \n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split data into features and labels\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)\n",
    "y = prefer_job_encoded\n",
    "\n",
    "# Standardize numerical columns\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c874201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"F1 Score (micro):\", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ac95c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c554626",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     26\u001b[0m     pipeline, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     31\u001b[0m lr \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     33\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression(max_iter=10000, random_state=42))\n",
    "]\n",
    "stacked_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Pipeline for feature scaling and PCA\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),  # Retain 95% variance\n",
    "    ('classifier', stacked_model)\n",
    "])\n",
    "\n",
    "# Hyperparameter Tuning with RandomizedSearch\n",
    "param_dist = {\n",
    "    'classifier__final_estimator__C': uniform(0.01, 10),\n",
    "    'classifier__final_estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'classifier__final_estimator__solver': ['saga']\n",
    "}\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_dist, n_iter=50, scoring='f1_micro', cv=5, random_state=42, verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "lr = grid_search.best_estimator_\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred_lr))\n",
    "print(\"F1 Score (micro):\", f1_score(y_test, y_pred_lr, average='micro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_lr, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4531871",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2e005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     26\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X_train\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: multi_output_rf\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m     29\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Evaluate the optimized model\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m evaluate_model(y_test, y_pred_test,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDicision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, f1_score\n",
    "\n",
    "# Define the base Random Forest model\n",
    "base_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(base_rf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1, n_iter=10)\n",
    "multi_output_rf = MultiOutputClassifier(random_search)\n",
    "\n",
    "# Fit the model on the training data\n",
    "multi_output_rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature Importance (optional: for numerical features only)\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': multi_output_rf.estimators_[0].best_estimator_.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "\n",
    "# Evaluate the optimized model\n",
    "evaluate_model(y_test, y_pred_test,\"Dicision Tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0feaaa",
   "metadata": {},
   "source": [
    "# Randorm Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c847d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# no of trees in random forest\n",
    "n_estimators=[20,60,100,120]\n",
    "# no of features\n",
    "max_features=[0.2,0.6,1.0]\n",
    "# max depth\n",
    "max_depth=[5,8,10]\n",
    "# max samples\n",
    "max_samples=[0.5,0.75,1.0]\n",
    "min_samples_split= [2, 5, 10]\n",
    "min_samples_leaf= [1, 2, 4]\n",
    "\n",
    "# 108 different random forest train\n",
    "\n",
    "param_grid={\n",
    "    \"n_estimators\":n_estimators,\n",
    "    \"max_features\":max_features,\n",
    "    \"max_depth\":max_depth,\n",
    "    \"max_samples\":max_samples,\n",
    "    \"min_samples_split\":min_samples_split,\n",
    "    \"min_samples_leaf\":min_samples_leaf,\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "#print(param_grid)\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf_grid=GridSearchCV(estimator=rf,\n",
    "                     param_grid=param_grid,\n",
    "                     cv=5,\n",
    "                     verbose=2,\n",
    "                     n_jobs=-1)\n",
    "rf_grid.fit(X_train,y_train)\n",
    "\n",
    "print(rf_grid.best_score_)\n",
    "rf_grid.best_params_\n",
    "\n",
    "y_pred_rf = rf_grid.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c97116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = MultiOutputClassifier(RandomForestClassifier(random_state=5))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = model.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c754be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = MultiOutputClassifier(RandomForestClassifier(random_state=42))\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b470154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate sample data\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_targets=3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Multi-output SVR\n",
    "model = MultiOutputRegressor(SVR())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ee05d",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53831076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb = OneVsRestClassifier(GradientBoostingClassifier(random_state=42))\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_gb, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade47c30",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b219a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 41.18%\n",
      "Hamming Loss: 0.06928104575163399\n",
      "F1 Score (micro): 0.6954022988505747\n",
      "F1 Score (macro): 0.5938438104316196\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "'''\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'estimator__max_depth': [3, 5, 10],\n",
    "    'estimator__n_estimators': [100, 200, 300],\n",
    "    'estimator__subsample': [0.8, 1.0],\n",
    "    'estimator__colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Grid Search with Cross Validation\n",
    "grid_search = GridSearchCV(OneVsRestClassifier(xgb.XGBClassifier(random_state=42)),param_grid=param_grid,\n",
    "    cv=3,scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_   '''\n",
    "\n",
    "xgb_model = OneVsRestClassifier(xgb.XGBClassifier(random_state=42))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred_xgb, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4089f",
   "metadata": {},
   "source": [
    "# Hard Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81fdc0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Hard Voting:\n",
      "Accuracy: 43.02%\n",
      "Hamming Loss: 0.06524547803617571\n",
      "F1 Score (micro): 0.6752411575562701\n",
      "F1 Score (macro): 0.46786643878842454\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting Classifier\n",
    "hard_voting = MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=100000, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "], voting='hard'))\n",
    "hard_voting.fit(X_train, y_train)\n",
    "y_pred_hv = hard_voting.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_hv, \"Hard Voting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd29c9",
   "metadata": {},
   "source": [
    "# Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "177ca59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Soft Voting:\n",
      "Accuracy: 43.02%\n",
      "Hamming Loss: 0.06718346253229975\n",
      "F1 Score (micro): 0.6867469879518072\n",
      "F1 Score (macro): 0.5099168008588298\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting Classifier\n",
    "soft_voting = MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=100000, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "], voting='soft'))\n",
    "soft_voting.fit(X_train, y_train)\n",
    "y_pred_sv = soft_voting.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_sv, \"Soft Voting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93778a9d",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa68f72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Support Vector Machines (SVM)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m svm \u001b[38;5;241m=\u001b[39m OneVsRestClassifier(SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m      3\u001b[0m svm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m y_pred_svm \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines (SVM)\n",
    "svm = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=42))\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_svm, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e353cdb",
   "metadata": {},
   "source": [
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a59c8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Neural Network:\n",
      "Accuracy: 46.51%\n",
      "Hamming Loss: 0.07428940568475452\n",
      "F1 Score (micro): 0.6723646723646723\n",
      "F1 Score (macro): 0.5590556327564045\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Classifier\n",
    "nn = MultiOutputClassifier(MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42))\n",
    "nn.fit(X_train, y_train)\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred_nn, \"Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34cafa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abroad</th>\n",
       "      <th>BCS</th>\n",
       "      <th>Bank Job</th>\n",
       "      <th>Business</th>\n",
       "      <th>Cyber Security</th>\n",
       "      <th>Data Analysis</th>\n",
       "      <th>Database Administration</th>\n",
       "      <th>Gaming</th>\n",
       "      <th>Govt Job</th>\n",
       "      <th>Hardware Sector</th>\n",
       "      <th>ML/AI Engineer</th>\n",
       "      <th>Management</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Other</th>\n",
       "      <th>Researcher</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Teaching</th>\n",
       "      <th>UI/UX Designing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>17.44%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>53.49%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>26.74%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>10.47%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>18.60%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>15.12%</td>\n",
       "      <td>53.49%</td>\n",
       "      <td>22.09%</td>\n",
       "      <td>3.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>16.28%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>55.81%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>19.77%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>55.81%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>2.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>18.60%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>53.49%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard Voting Classifier</th>\n",
       "      <td>19.77%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>56.98%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting Classifier</th>\n",
       "      <td>23.26%</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>10.47%</td>\n",
       "      <td>54.65%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>1.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>16.28%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>10.47%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>12.79%</td>\n",
       "      <td>51.16%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>19.77%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>18.60%</td>\n",
       "      <td>54.65%</td>\n",
       "      <td>9.30%</td>\n",
       "      <td>1.16%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Abroad     BCS Bank Job Business Cyber Security  \\\n",
       "Logistic Regression     17.44%   4.65%    3.49%    2.33%          6.98%   \n",
       "Decision Tree           26.74%  11.63%    9.30%    5.81%         12.79%   \n",
       "Random Forest           16.28%   2.33%    1.16%    2.33%          8.14%   \n",
       "XGBoost Classifier      19.77%   6.98%    5.81%    4.65%         11.63%   \n",
       "Gradient Boosting       18.60%   5.81%    5.81%    2.33%          9.30%   \n",
       "Hard Voting Classifier  19.77%   3.49%    1.16%    3.49%          8.14%   \n",
       "Soft Voting Classifier  23.26%   8.14%    1.16%    3.49%          9.30%   \n",
       "SVM                     16.28%   3.49%    2.33%    0.00%          6.98%   \n",
       "Neural Network          19.77%   4.65%    5.81%    4.65%          9.30%   \n",
       "\n",
       "                       Data Analysis Database Administration Gaming Govt Job  \\\n",
       "Logistic Regression            9.30%                   1.16%  1.16%    4.65%   \n",
       "Decision Tree                 13.95%                  10.47%  0.00%   13.95%   \n",
       "Random Forest                  6.98%                   1.16%  0.00%    4.65%   \n",
       "XGBoost Classifier            13.95%                   3.49%  0.00%    4.65%   \n",
       "Gradient Boosting              9.30%                   4.65%  0.00%    4.65%   \n",
       "Hard Voting Classifier         8.14%                   1.16%  0.00%    4.65%   \n",
       "Soft Voting Classifier        11.63%                   3.49%  0.00%    8.14%   \n",
       "SVM                           10.47%                   0.00%  1.16%    1.16%   \n",
       "Neural Network                11.63%                   5.81%  1.16%    9.30%   \n",
       "\n",
       "                       Hardware Sector ML/AI Engineer Management Networking  \\\n",
       "Logistic Regression              1.16%         13.95%      0.00%      6.98%   \n",
       "Decision Tree                    0.00%         18.60%      6.98%     12.79%   \n",
       "Random Forest                    0.00%         11.63%      3.49%      2.33%   \n",
       "XGBoost Classifier               1.16%         13.95%      4.65%      4.65%   \n",
       "Gradient Boosting                0.00%         11.63%      4.65%      3.49%   \n",
       "Hard Voting Classifier           0.00%         12.79%      3.49%      3.49%   \n",
       "Soft Voting Classifier           0.00%         13.95%      3.49%      3.49%   \n",
       "SVM                              2.33%         13.95%      0.00%      0.00%   \n",
       "Neural Network                   0.00%         13.95%      3.49%      4.65%   \n",
       "\n",
       "                        Other Researcher Software Development Teaching  \\\n",
       "Logistic Regression     4.65%     12.79%               53.49%    5.81%   \n",
       "Decision Tree           6.98%     15.12%               53.49%   22.09%   \n",
       "Random Forest           6.98%     12.79%               55.81%    5.81%   \n",
       "XGBoost Classifier      6.98%     11.63%               55.81%    5.81%   \n",
       "Gradient Boosting       6.98%     13.95%               53.49%    9.30%   \n",
       "Hard Voting Classifier  6.98%     12.79%               56.98%    5.81%   \n",
       "Soft Voting Classifier  6.98%     10.47%               54.65%    9.30%   \n",
       "SVM                     6.98%     12.79%               51.16%    0.00%   \n",
       "Neural Network          4.65%     18.60%               54.65%    9.30%   \n",
       "\n",
       "                       UI/UX Designing  \n",
       "Logistic Regression              0.00%  \n",
       "Decision Tree                    3.49%  \n",
       "Random Forest                    0.00%  \n",
       "XGBoost Classifier               2.33%  \n",
       "Gradient Boosting                0.00%  \n",
       "Hard Voting Classifier           0.00%  \n",
       "Soft Voting Classifier           1.16%  \n",
       "SVM                              0.00%  \n",
       "Neural Network                   1.16%  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to create a DataFrame with algorithms as rows and job categories as columns\n",
    "def predictions_to_dataframe(y_preds, model_names, job_categories):\n",
    "    predictions_dict = {}\n",
    "    for y_pred, model_name in zip(y_preds, model_names):\n",
    "        model_predictions = []\n",
    "        for category in job_categories:\n",
    "            prediction_percentage = (y_pred[:, mlb_prefer_job.classes_ == category].sum() / len(y_pred)) * 100\n",
    "            model_predictions.append(f\"{prediction_percentage:.2f}%\")\n",
    "        predictions_dict[model_name] = model_predictions\n",
    "    predictions_df = pd.DataFrame(predictions_dict, index=job_categories)\n",
    "    return predictions_df\n",
    "\n",
    "# Get job categories from MultiLabelBinarizer\n",
    "job_categories = mlb_prefer_job.classes_\n",
    "\n",
    "# Collect predictions and model names\n",
    "y_preds = [y_pred_lr, y_pred_dt, y_pred_rf, y_pred_xgb, y_pred_gb, y_pred_hv, y_pred_sv,y_pred_svm, y_pred_nn]\n",
    "model_names = [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"XGBoost Classifier\", \n",
    "               \"Gradient Boosting\", \"Hard Voting Classifier\", \"Soft Voting Classifier\",\"SVM\",\"Neural Network\"]\n",
    "\n",
    "\n",
    "predictions_df = predictions_to_dataframe(y_preds, model_names, job_categories)\n",
    "\n",
    "predictions_df = predictions_df.T\n",
    "#predictions_df.to_csv('predictions.csv')\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db6cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf4e109",
   "metadata": {},
   "source": [
    "# check Accuracy & Hamming Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "536c9f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "Accuracy: 16.28%\n",
      "Hamming Loss: 0.10852713178294573\n",
      "F1 Score (micro): 0.4846625766871166\n",
      "F1 Score (macro): 0.28873587496775904\n",
      "\n",
      "\n",
      "Results for Decision Tree:\n",
      "Accuracy: 37.21%\n",
      "Hamming Loss: 0.10400516795865633\n",
      "F1 Score (micro): 0.6044226044226044\n",
      "F1 Score (macro): 0.4680448794343853\n",
      "\n",
      "\n",
      "Results for Random Forest:\n",
      "Accuracy: 47.67%\n",
      "Hamming Loss: 0.0665374677002584\n",
      "F1 Score (micro): 0.677115987460815\n",
      "F1 Score (macro): 0.4885383448579247\n",
      "\n",
      "\n",
      "Results for Gradient Boosting:\n",
      "Accuracy: 41.86%\n",
      "Hamming Loss: 0.0710594315245478\n",
      "F1 Score (micro): 0.6745562130177515\n",
      "F1 Score (macro): 0.4936730338904252\n",
      "\n",
      "\n",
      "Results for XGBoost Classifier:\n",
      "Accuracy: 52.33%\n",
      "Hamming Loss: 0.059431524547803614\n",
      "F1 Score (micro): 0.7371428571428571\n",
      "F1 Score (macro): 0.630696860991674\n",
      "\n",
      "\n",
      "Results for Hard Voting Classifier:\n",
      "Accuracy: 47.67%\n",
      "Hamming Loss: 0.06718346253229975\n",
      "F1 Score (micro): 0.6829268292682926\n",
      "F1 Score (macro): 0.49049256949901565\n",
      "\n",
      "\n",
      "Results for Soft Voting Classifier:\n",
      "Accuracy: 46.51%\n",
      "Hamming Loss: 0.06912144702842377\n",
      "F1 Score (micro): 0.6898550724637681\n",
      "F1 Score (macro): 0.5230325152051907\n",
      "\n",
      "\n",
      "Results for Neural Network:\n",
      "Accuracy: 46.51%\n",
      "Hamming Loss: 0.07622739018087855\n",
      "F1 Score (micro): 0.6666666666666667\n",
      "F1 Score (macro): 0.5354746960819067\n",
      "\n",
      "\n",
      "Results for SVM:\n",
      "Accuracy: 22.09%\n",
      "Hamming Loss: 0.1020671834625323\n",
      "F1 Score (micro): 0.487012987012987\n",
      "F1 Score (macro): 0.27175656923202507\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"F1 Score (micro):\", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluate each model\n",
    "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "evaluate_model(y_test, y_pred_gb, \"Gradient Boosting\")\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost Classifier\")\n",
    "evaluate_model(y_test, y_pred_hv, \"Hard Voting Classifier\")\n",
    "evaluate_model(y_test, y_pred_sv, \"Soft Voting Classifier\")\n",
    "evaluate_model(y_test, y_pred_nn, \"Neural Network\")\n",
    "evaluate_model(y_test, y_pred_svm, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c465c4d",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb3ecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data shape : (430, 25)\n",
      "training data shape :  (344, 25)\n",
      "test data shape :  (86, 25)\n",
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Abroad: 94.67%\n",
      "Researcher: 36.08%\n",
      "Teaching: 4.82%\n",
      "Cyber Security: 1.88%\n",
      "Data Analysis: 1.66%\n",
      "Software Development: 1.52%\n",
      "UI/UX Designing: 1.14%\n",
      "Database Administration: 0.72%\n",
      "Gaming: 0.67%\n",
      "Networking: 0.25%\n",
      "Business: 0.19%\n",
      "Management: 0.19%\n",
      "ML/AI Engineer: 0.17%\n",
      "Bank Job: 0.16%\n",
      "Other: 0.13%\n",
      "BCS: 0.09%\n",
      "Hardware Sector: 0.04%\n",
      "Govt Job: 0.02%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string \n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job'] \n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"full data shape :\",X.shape)\n",
    "print(\"training data shape : \",X_train.shape)\n",
    "print(\"test data shape : \",X_test.shape)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = OneVsRestClassifier(xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained XGBoost model\n",
    "    y_pred_prob = xgb_model.predict_proba(input_df)\n",
    "\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.9,\n",
    "    'Critical Thinking': 2,\n",
    "    'Problem Solving': 0,\n",
    "    'Team Work': 0,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 1,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 2,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 0,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1, \n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 3,\n",
    "    'publication': 5,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581db2e9",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d4aebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22093023255813954\n",
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Abroad: 97.15%\n",
      "Researcher: 74.96%\n",
      "Data Analysis: 41.94%\n",
      "Software Development: 14.93%\n",
      "Networking: 14.82%\n",
      "Teaching: 13.88%\n",
      "BCS: 13.78%\n",
      "Govt Job: 13.14%\n",
      "Database Administration: 12.00%\n",
      "Bank Job: 7.02%\n",
      "Cyber Security: 6.82%\n",
      "Management: 6.00%\n",
      "UI/UX Designing: 5.32%\n",
      "Other: 5.29%\n",
      "ML/AI Engineer: 3.37%\n",
      "Business: 1.19%\n",
      "Gaming: 0.19%\n",
      "Hardware Sector: 0.11%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Assuming you have already read and processed your data similar to previous examples\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "svm_model = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=42))\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained SVM model\n",
    "    y_pred_prob = svm_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.9,\n",
    "    'Critical Thinking': 2,\n",
    "    'Problem Solving': 0,\n",
    "    'Team Work': 0,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 1,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 2,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 0,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1, \n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 3,\n",
    "    'publication': 5,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "y_pred= svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1571d4",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41377220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47674418604651164\n",
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Abroad: 80.00%\n",
      "Researcher: 51.00%\n",
      "Data Analysis: 27.00%\n",
      "ML/AI Engineer: 27.00%\n",
      "Software Development: 26.00%\n",
      "Other: 20.00%\n",
      "Teaching: 20.00%\n",
      "Cyber Security: 19.00%\n",
      "Bank Job: 18.00%\n",
      "BCS: 14.00%\n",
      "Database Administration: 12.00%\n",
      "Govt Job: 8.00%\n",
      "Management: 7.00%\n",
      "Business: 6.00%\n",
      "Gaming: 6.00%\n",
      "UI/UX Designing: 6.00%\n",
      "Hardware Sector: 3.00%\n",
      "Networking: 2.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already read and processed your data similar to previous examples\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string if necessary (already done in your case)\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RandomForest Classifier\n",
    "rfc_model = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred= rfc_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_, index=input_df.index)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained RandomForest model\n",
    "    y_pred_prob = rfc_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.9,\n",
    "    'Critical Thinking': 2,\n",
    "    'Problem Solving': 0,\n",
    "    'Team Work': 0,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 1,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 2,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 0,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1, \n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 3,\n",
    "    'publication': 5,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83eb2b",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652e71f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Software Development: 100.00%\n",
      "ML/AI Engineer: 27.57%\n",
      "Other: 4.13%\n",
      "Data Analysis: 2.80%\n",
      "Database Administration: 1.33%\n",
      "Cyber Security: 0.52%\n",
      "Management: 0.46%\n",
      "Abroad: 0.01%\n",
      "Business: 0.00%\n",
      "UI/UX Designing: 0.00%\n",
      "Gaming: 0.00%\n",
      "Teaching: 0.00%\n",
      "Researcher: 0.00%\n",
      "Govt Job: 0.00%\n",
      "Hardware Sector: 0.00%\n",
      "Networking: 0.00%\n",
      "Bank Job: 0.00%\n",
      "BCS: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Assuming you have already read and processed your data similar to previous examples\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string if necessary (already done in your case)\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_model = OneVsRestClassifier(MLPClassifier(random_state=42, max_iter=1000))\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_, index=input_df.index)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained MLP model\n",
    "    y_pred_prob = mlp_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.7,\n",
    "    'Critical Thinking': 1,\n",
    "    'Problem Solving': 3,\n",
    "    'Team Work': 3,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 3,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 3,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 2,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1,  # Check spelling against X_train columns\n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 0,\n",
    "    'publication': 0,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c335b",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5271fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Abroad  BCS  Bank Job  Business  Cyber Security  Data Analysis  \\\n",
      "0         0    0         0         0               0              0   \n",
      "1         0    0         0         0               0              0   \n",
      "2         0    0         0         0               0              0   \n",
      "3         0    0         0         0               0              0   \n",
      "4         0    0         0         0               0              0   \n",
      "..      ...  ...       ...       ...             ...            ...   \n",
      "425       0    0         0         0               0              0   \n",
      "426       0    1         1         0               0              0   \n",
      "427       1    0         0         0               0              0   \n",
      "428       0    0         0         0               0              1   \n",
      "429       0    0         0         0               0              0   \n",
      "\n",
      "     Database Administration  Gaming  Govt Job  Hardware Sector  \\\n",
      "0                          0       0         0                0   \n",
      "1                          0       0         0                0   \n",
      "2                          0       0         0                0   \n",
      "3                          0       0         0                0   \n",
      "4                          0       0         0                0   \n",
      "..                       ...     ...       ...              ...   \n",
      "425                        0       0         0                0   \n",
      "426                        0       0         1                0   \n",
      "427                        0       0         0                0   \n",
      "428                        0       0         0                0   \n",
      "429                        0       0         0                0   \n",
      "\n",
      "     ML/AI Engineer  Management  Networking  Other  Researcher  \\\n",
      "0                 0           0           0      0           0   \n",
      "1                 0           0           0      0           0   \n",
      "2                 0           0           0      0           0   \n",
      "3                 0           0           0      0           0   \n",
      "4                 0           0           0      0           0   \n",
      "..              ...         ...         ...    ...         ...   \n",
      "425               0           0           0      0           0   \n",
      "426               0           0           0      0           0   \n",
      "427               0           0           0      0           1   \n",
      "428               1           0           0      0           0   \n",
      "429               0           0           0      0           0   \n",
      "\n",
      "     Software Development  Teaching  UI/UX Designing  \n",
      "0                       1         0                0  \n",
      "1                       0         1                0  \n",
      "2                       1         0                0  \n",
      "3                       1         0                0  \n",
      "4                       1         0                0  \n",
      "..                    ...       ...              ...  \n",
      "425                     1         0                0  \n",
      "426                     0         0                0  \n",
      "427                     0         0                0  \n",
      "428                     0         0                0  \n",
      "429                     0         0                1  \n",
      "\n",
      "[430 rows x 18 columns]\n",
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Software Development: 96.23%\n",
      "ML/AI Engineer: 64.89%\n",
      "Data Analysis: 52.62%\n",
      "Database Administration: 30.77%\n",
      "Abroad: 17.38%\n",
      "Other: 7.92%\n",
      "Teaching: 2.12%\n",
      "Business: 1.85%\n",
      "Cyber Security: 1.80%\n",
      "Networking: 1.51%\n",
      "Management: 1.34%\n",
      "Govt Job: 0.76%\n",
      "Researcher: 0.63%\n",
      "Bank Job: 0.40%\n",
      "UI/UX Designing: 0.28%\n",
      "BCS: 0.18%\n",
      "Gaming: 0.00%\n",
      "Hardware Sector: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string if necessary (already done in your case)\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "print(prefer_job_encoded)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression with OneVsRestClassifier\n",
    "lr_model = OneVsRestClassifier(LogisticRegression(max_iter=1000))  # Increase max_iter if necessary\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_, index=input_df.index)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained Logistic Regression model\n",
    "    y_pred_prob = lr_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.7,\n",
    "    'Critical Thinking': 1,\n",
    "    'Problem Solving': 2,\n",
    "    'Team Work': 3,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 2,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 3,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 2,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1,  # Check spelling against X_train columns\n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 0,\n",
    "    'publication': 0,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4970ab",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "\n",
    "*Evaluate the models using metrics such as accuracy, precision, recall, F1-score, and ROC-AUC.\n",
    "\n",
    "\n",
    "\n",
    "*Use cross-validation to ensure the model's robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4204d223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Logistic Regression:\n",
      "Accuracy: 0.15\n",
      "Precision: 0.41\n",
      "Recall: 0.22\n",
      "\n",
      "\n",
      "Evaluating Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Decision Tree:\n",
      "Accuracy: 0.33\n",
      "Precision: 0.48\n",
      "Recall: 0.51\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Random Forest:\n",
      "Accuracy: 0.44\n",
      "Precision: 0.70\n",
      "Recall: 0.44\n",
      "\n",
      "\n",
      "Evaluating Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Gradient Boosting:\n",
      "Accuracy: 0.32\n",
      "Precision: 0.63\n",
      "Recall: 0.43\n",
      "\n",
      "\n",
      "Evaluating XGBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for XGBoost Classifier:\n",
      "Accuracy: 0.40\n",
      "Precision: 0.64\n",
      "Recall: 0.51\n",
      "\n",
      "\n",
      "Evaluating Hard Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Hard Voting Classifier:\n",
      "Accuracy: 0.42\n",
      "Precision: 0.69\n",
      "Recall: 0.44\n",
      "\n",
      "\n",
      "Evaluating Soft Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Soft Voting Classifier:\n",
      "Accuracy: 0.39\n",
      "Precision: 0.67\n",
      "Recall: 0.48\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "# Convert 'Prefer Job' and 'Influencing Factor' columns to string and split into lists\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']), columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']), columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original columns and combine encoded features with the dataframe\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)\n",
    "y = prefer_job_encoded\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the features (excluding categorical columns)\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Splitting into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': OneVsRestClassifier(LogisticRegression(max_iter=10000, random_state=42)),\n",
    "    'Decision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=42)),\n",
    "    'Random Forest': MultiOutputClassifier(RandomForestClassifier(random_state=42)),\n",
    "    'Gradient Boosting': OneVsRestClassifier(GradientBoostingClassifier(random_state=42)),\n",
    "    'XGBoost Classifier': OneVsRestClassifier(xgb.XGBClassifier(random_state=42)),\n",
    "    'Hard Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='hard')),\n",
    "    'Soft Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='soft'))\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']\n",
    "\n",
    "# Perform cross-validation and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Extract and print evaluation metrics\n",
    "    accuracy = cv_results['test_accuracy'].mean()\n",
    "    precision = cv_results['test_precision_macro'].mean()\n",
    "    recall = cv_results['test_recall_macro'].mean()\n",
    "    #f1 = cv_results['test_f1_macro'].mean()\n",
    "   # roc_auc = cv_results['test_roc_auc_ovr'].mean()\n",
    "    \n",
    "    print(f\"Cross-validation results for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    #print(f\"F1-score: {f1:.2f}\")\n",
    "   # print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecb87f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Logistic Regression:\n",
      "Accuracy: 0.23\n",
      "Precision: 0.38\n",
      "Recall: 0.23\n",
      "F1-score: 0.26\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n",
      "Evaluating Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Decision Tree:\n",
      "Accuracy: 0.24\n",
      "Precision: 0.47\n",
      "Recall: 0.54\n",
      "F1-score: 0.49\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Random Forest:\n",
      "Accuracy: 0.46\n",
      "Precision: 0.62\n",
      "Recall: 0.38\n",
      "F1-score: 0.45\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n",
      "Evaluating Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Gradient Boosting:\n",
      "Accuracy: 0.44\n",
      "Precision: 0.63\n",
      "Recall: 0.49\n",
      "F1-score: 0.52\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n",
      "Evaluating XGBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for XGBoost Classifier:\n",
      "Accuracy: 0.39\n",
      "Precision: 0.55\n",
      "Recall: 0.40\n",
      "F1-score: 0.44\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n",
      "Evaluating Hard Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Hard Voting Classifier:\n",
      "Accuracy: 0.39\n",
      "Precision: 0.58\n",
      "Recall: 0.37\n",
      "F1-score: 0.43\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n",
      "Evaluating Soft Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Soft Voting Classifier:\n",
      "Accuracy: 0.42\n",
      "Precision: 0.62\n",
      "Recall: 0.50\n",
      "F1-score: 0.53\n",
      "ROC-AUC: nan\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"rrr_data.csv\")\n",
    "\n",
    "# Convert 'Prefer Job' and 'Influencing Factor' columns to string and split into lists\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']), columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']), columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original columns and combine encoded features with the dataframe\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)\n",
    "y = prefer_job_encoded\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the features (excluding categorical columns)\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Splitting into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': OneVsRestClassifier(LogisticRegression(max_iter=10000, random_state=42)),\n",
    "    'Decision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=42)),\n",
    "    'Random Forest': MultiOutputClassifier(RandomForestClassifier(random_state=42)),\n",
    "    'Gradient Boosting': OneVsRestClassifier(GradientBoostingClassifier(random_state=42)),\n",
    "    'XGBoost Classifier': OneVsRestClassifier(xgb.XGBClassifier(random_state=42)),\n",
    "    'Hard Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='hard')),\n",
    "    'Soft Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='soft'))\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']\n",
    "\n",
    "# Perform cross-validation and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Extract and print evaluation metrics\n",
    "    accuracy = cv_results['test_accuracy'].mean()\n",
    "    precision = cv_results['test_precision_macro'].mean()\n",
    "    recall = cv_results['test_recall_macro'].mean()\n",
    "    f1 = cv_results['test_f1_macro'].mean()\n",
    "    roc_auc = cv_results['test_roc_auc_ovr'].mean()\n",
    "    \n",
    "    print(f\"Cross-validation results for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715c30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e701cf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Leadership & Professional Attitude\n- Mass Communication\n- Professional Writing\n- Public Speaking\n- Unnamed: 0\n- ...\nFeature names seen at fit time, yet now missing:\n- Communication Skill\n- Other Factor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Apply the new threshold-based prediction and evaluation for each model\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m y_pred_lr_threshold \u001b[38;5;241m=\u001b[39m predict_with_threshold(lr, X_test)\n\u001b[0;32m     24\u001b[0m evaluate_model_thresholded(y_test, y_pred_lr_threshold, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m y_pred_rf_threshold \u001b[38;5;241m=\u001b[39m predict_with_threshold(rf, X_test)\n",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m, in \u001b[0;36mpredict_with_threshold\u001b[1;34m(model, X_test, threshold)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_with_threshold\u001b[39m(model, X_test, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Get the probability distribution (predict_proba) for models that support it\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Convert probabilities into binary predictions based on the threshold\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# proba is a list of arrays, so we iterate over it and apply the threshold\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mwhere(p \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m proba])\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multiclass.py:494\u001b[0m, in \u001b[0;36mOneVsRestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    491\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# Y[i, j] gives the probability that sample i has the label j.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# In the multi-label case, these are not disjoint.\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([e\u001b[38;5;241m.\u001b[39mpredict_proba(X)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;66;03m# Only one estimator, but we still want to return probabilities\u001b[39;00m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# for two classes.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Y), Y), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multiclass.py:494\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    491\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# Y[i, j] gives the probability that sample i has the label j.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# In the multi-label case, these are not disjoint.\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([e\u001b[38;5;241m.\u001b[39mpredict_proba(X)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;66;03m# Only one estimator, but we still want to return probabilities\u001b[39;00m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# for two classes.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Y), Y), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1383\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1375\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1380\u001b[0m     )\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[1;32m-> 1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_predict_proba_lr(X)\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:466\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    467\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Leadership & Professional Attitude\n- Mass Communication\n- Professional Writing\n- Public Speaking\n- Unnamed: 0\n- ...\nFeature names seen at fit time, yet now missing:\n- Communication Skill\n- Other Factor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Update softmax prediction logic for multi-label classification\n",
    "def predict_with_threshold(model, X_test, threshold=0.5):\n",
    "    # Get the probability distribution (predict_proba) for models that support it\n",
    "    proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Convert probabilities into binary predictions based on the threshold\n",
    "    # proba is a list of arrays, so we iterate over it and apply the threshold\n",
    "    return np.array([np.where(p >= threshold, 1, 0) for p in proba]).T\n",
    "\n",
    "# Evaluate models using thresholded predictions for multi-label classification\n",
    "def evaluate_model_thresholded(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"F1 Score (micro):\", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Apply the new threshold-based prediction and evaluation for each model\n",
    "y_pred_lr_threshold = predict_with_threshold(lr, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_lr_threshold, \"Logistic Regression\")\n",
    "\n",
    "y_pred_rf_threshold = predict_with_threshold(rf, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_rf_threshold, \"Random Forest\")\n",
    "\n",
    "y_pred_gb_threshold = predict_with_threshold(gb, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_gb_threshold, \"Gradient Boosting\")\n",
    "\n",
    "y_pred_xgb_threshold = predict_with_threshold(xgb_model, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_xgb_threshold, \"XGBoost Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bd0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f96bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
