{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e20da21",
   "metadata": {},
   "source": [
    "# Preprocessing:\n",
    "\n",
    "*Encode categorical data (e.g., 'Influencing Factor', 'Preferred Job') using one-hot encoding or MultiLabelBinarizer.\n",
    "\n",
    "\n",
    "\n",
    "*Normalize numerical data (e.g., CGPA, skill ratings) using StandardScaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec4223b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>Critical Thinking</th>\n",
       "      <th>Problem Solving</th>\n",
       "      <th>Team Work</th>\n",
       "      <th>Communication Skill</th>\n",
       "      <th>Software Engineering Principal</th>\n",
       "      <th>Data Structure &amp; Algorithm</th>\n",
       "      <th>Database Management</th>\n",
       "      <th>Data Analysis skill</th>\n",
       "      <th>Web Developing Skill</th>\n",
       "      <th>...</th>\n",
       "      <th>Govt Job</th>\n",
       "      <th>Hardware Sector</th>\n",
       "      <th>ML/AI Engineer</th>\n",
       "      <th>Management</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Other</th>\n",
       "      <th>Researcher</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Teaching</th>\n",
       "      <th>UI/UX Designing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.84</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  Critical Thinking  Problem Solving  Team Work  Communication Skill  \\\n",
       "0  3.84                  2                2          3                    2   \n",
       "1  2.50                  1                1          1                    1   \n",
       "2  3.34                  2                2          2                    1   \n",
       "3  3.78                  2                2          2                    2   \n",
       "4  3.00                  2                2          3                    2   \n",
       "5  3.30                  0                3          3                    3   \n",
       "6  3.30                  1                1          1                    1   \n",
       "7  3.10                  2                2          1                    1   \n",
       "8  3.91                  1                1          2                    2   \n",
       "9  3.25                  2                1          2                    1   \n",
       "\n",
       "   Software Engineering Principal  Data Structure & Algorithm  \\\n",
       "0                               2                           3   \n",
       "1                               1                           1   \n",
       "2                               1                           2   \n",
       "3                               1                           2   \n",
       "4                               2                           2   \n",
       "5                               2                           2   \n",
       "6                               1                           1   \n",
       "7                               2                           2   \n",
       "8                               1                           1   \n",
       "9                               1                           2   \n",
       "\n",
       "   Database Management  Data Analysis skill  Web Developing Skill  ...  \\\n",
       "0                    2                    2                     1  ...   \n",
       "1                    1                    1                     2  ...   \n",
       "2                    1                    1                     1  ...   \n",
       "3                    2                    1                     1  ...   \n",
       "4                    3                    3                     3  ...   \n",
       "5                    3                    3                     3  ...   \n",
       "6                    1                    1                     1  ...   \n",
       "7                    2                    3                     1  ...   \n",
       "8                    1                    1                     1  ...   \n",
       "9                    2                    2                     3  ...   \n",
       "\n",
       "   Govt Job  Hardware Sector  ML/AI Engineer  Management  Networking  Other  \\\n",
       "0         0                0               0           0           0      0   \n",
       "1         0                0               0           0           0      0   \n",
       "2         0                0               0           0           0      0   \n",
       "3         0                0               0           0           0      0   \n",
       "4         0                0               0           0           0      0   \n",
       "5         0                0               0           0           0      0   \n",
       "6         0                0               0           0           0      0   \n",
       "7         0                0               0           0           0      0   \n",
       "8         0                0               0           0           0      0   \n",
       "9         0                0               0           0           0      0   \n",
       "\n",
       "   Researcher  Software Development  Teaching  UI/UX Designing  \n",
       "0           0                     1         0                0  \n",
       "1           0                     0         1                0  \n",
       "2           0                     1         0                0  \n",
       "3           0                     1         0                0  \n",
       "4           0                     1         0                0  \n",
       "5           0                     1         0                0  \n",
       "6           0                     1         0                0  \n",
       "7           0                     1         0                0  \n",
       "8           0                     0         0                0  \n",
       "9           0                     0         0                0  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert 'Prefer Job' and 'Influencing Factor' columns to string\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Splitting the multi-level categorical data into lists and strip extra spaces\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor'\n",
    "mlb = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb.fit_transform(df['Influencing Factor']), columns=mlb.classes_, index=df.index)\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Prefer Job'\n",
    "prefer_job_encoded = pd.DataFrame(mlb.fit_transform(df['Prefer Job']), columns=mlb.classes_, index=df.index)\n",
    "\n",
    "# Combining encoded features with the original dataframe\n",
    "df_encoded = pd.concat([df.drop(['Influencing Factor', 'Prefer Job'], axis=1), influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "df_encoded.head(10)\n",
    "#df_encoded.to_csv(\"preprocess_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93d687",
   "metadata": {},
   "source": [
    "# Feature Engineering:\n",
    "*Create new features by combining existing ones, such as average skill rating or the total number of projects/publications.\n",
    "\n",
    "\n",
    "\n",
    "*Use Principal Component Analysis (PCA) to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939e4039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>Critical Thinking</th>\n",
       "      <th>Problem Solving</th>\n",
       "      <th>Team Work</th>\n",
       "      <th>Communication Skill</th>\n",
       "      <th>Software Engineering Principal</th>\n",
       "      <th>Data Structure &amp; Algorithm</th>\n",
       "      <th>Database Management</th>\n",
       "      <th>Data Analysis skill</th>\n",
       "      <th>Web Developing Skill</th>\n",
       "      <th>...</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Other</th>\n",
       "      <th>Researcher</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Teaching</th>\n",
       "      <th>UI/UX Designing</th>\n",
       "      <th>Average Skill Rating</th>\n",
       "      <th>Total Projects/Publications</th>\n",
       "      <th>Skill Diversity</th>\n",
       "      <th>ML_DA_Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.84</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.623158</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333684</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.78</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.567368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.263158</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>3.46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.603158</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>3.22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.643158</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>3.39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.125789</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>3.45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.286842</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.305789</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cgpa  Critical Thinking  Problem Solving  Team Work  Communication Skill  \\\n",
       "0    3.84                  2                2          3                    2   \n",
       "1    2.50                  1                1          1                    1   \n",
       "2    3.34                  2                2          2                    1   \n",
       "3    3.78                  2                2          2                    2   \n",
       "4    3.00                  2                2          3                    2   \n",
       "..    ...                ...              ...        ...                  ...   \n",
       "420  3.46                  2                2          3                    0   \n",
       "421  3.22                  2                3          3                    3   \n",
       "422  3.39                  2                2          2                    2   \n",
       "423  3.45                  1                2          2                    2   \n",
       "424  3.81                  1                2          2                    3   \n",
       "\n",
       "     Software Engineering Principal  Data Structure & Algorithm  \\\n",
       "0                                 2                           3   \n",
       "1                                 1                           1   \n",
       "2                                 1                           2   \n",
       "3                                 1                           2   \n",
       "4                                 2                           2   \n",
       "..                              ...                         ...   \n",
       "420                               1                           1   \n",
       "421                               3                           3   \n",
       "422                               2                           1   \n",
       "423                               2                           3   \n",
       "424                               1                           2   \n",
       "\n",
       "     Database Management  Data Analysis skill  Web Developing Skill  ...  \\\n",
       "0                      2                    2                     1  ...   \n",
       "1                      1                    1                     2  ...   \n",
       "2                      1                    1                     1  ...   \n",
       "3                      2                    1                     1  ...   \n",
       "4                      3                    3                     3  ...   \n",
       "..                   ...                  ...                   ...  ...   \n",
       "420                    2                    2                     1  ...   \n",
       "421                    3                    2                     3  ...   \n",
       "422                    2                    2                     2  ...   \n",
       "423                    3                    3                     2  ...   \n",
       "424                    3                    3                     1  ...   \n",
       "\n",
       "     Networking  Other  Researcher  Software Development  Teaching  \\\n",
       "0             0      0           0                     1         0   \n",
       "1             0      0           0                     0         1   \n",
       "2             0      0           0                     1         0   \n",
       "3             0      0           0                     1         0   \n",
       "4             0      0           0                     1         0   \n",
       "..          ...    ...         ...                   ...       ...   \n",
       "420           0      0           0                     0         0   \n",
       "421           0      0           0                     1         0   \n",
       "422           1      0           0                     0         0   \n",
       "423           0      0           0                     0         0   \n",
       "424           0      0           1                     0         0   \n",
       "\n",
       "     UI/UX Designing  Average Skill Rating  Total Projects/Publications  \\\n",
       "0                  0              1.623158                            3   \n",
       "1                  0              1.026316                            0   \n",
       "2                  0              1.333684                            2   \n",
       "3                  0              1.567368                            1   \n",
       "4                  0              2.263158                            5   \n",
       "..               ...                   ...                          ...   \n",
       "420                0              1.603158                            2   \n",
       "421                0              2.643158                            6   \n",
       "422                0              2.125789                            3   \n",
       "423                0              2.286842                            4   \n",
       "424                0              2.305789                            7   \n",
       "\n",
       "     Skill Diversity  ML_DA_Combination  \n",
       "0                  3               True  \n",
       "1                  1               True  \n",
       "2                  1               True  \n",
       "3                  1               True  \n",
       "4                  8               True  \n",
       "..               ...                ...  \n",
       "420                2               True  \n",
       "421               11               True  \n",
       "422                5               True  \n",
       "423                8               True  \n",
       "424                8               True  \n",
       "\n",
       "[425 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Calculate average skill rating\n",
    "\n",
    "skills = ['cgpa', \n",
    "          'Critical Thinking', \n",
    "          'Problem Solving', \n",
    "          'Team Work', \n",
    "          'Communication Skill', \n",
    "          'Software Engineering Principal',\n",
    "          'Data Structure & Algorithm', \n",
    "          'Database Management', \n",
    "          'Data Analysis skill', \n",
    "          'Web Developing Skill', \n",
    "          'Understanding of computer architecture & System',\n",
    "          'Understanding Operating System', \n",
    "          'Networking Concept',\n",
    "          'Cyber Security Skill',\n",
    "          'Machine Learning Skill', \n",
    "          'Robotics Skill',\n",
    "          'Research Skill',\n",
    "          'publication',\n",
    "          'project'\n",
    "         ]\n",
    "df_encoded['Average Skill Rating'] = df_encoded[skills].mean(axis=1)\n",
    "\n",
    "\n",
    "# Example: Calculate total projects and publications\n",
    "df_encoded['Total Projects/Publications'] = df_encoded['project'] + df_encoded['publication']\n",
    "\n",
    "\n",
    "\n",
    "# Example: Count skills rated above a certain threshold\n",
    "threshold = 2  # Example threshold for skill rating\n",
    "df_encoded['Skill Diversity'] = (df_encoded[skills] > threshold).sum(axis=1)\n",
    "\n",
    "\n",
    "# Example: Create a feature for Machine Learning and Data Analysis combination\n",
    "df_encoded['ML_DA_Combination'] = (df_encoded['Machine Learning Skill'] > 0) & (df_encoded['Data Analysis skill'] > 0)\n",
    "\n",
    "\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1d90c",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60ec688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.20677266 0.07131099 0.06071917 0.05272071 0.05020086 0.03899241\n",
      " 0.03587482 0.03355139 0.02907997 0.02613686 0.02514138 0.02480502]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Assuming df_encoded and other variables are defined as in your previous code\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_encoded)  # Assuming 'Student ID' is not a feature\n",
    "\n",
    "# Initialize PCA with desired number of components\n",
    "n_components = 12  # Example: Reduce to 10 principal components\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit PCA and transform data\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Visualize cumulative explained variance ratio\n",
    "plt.plot(range(1, n_components+1), np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('PCA - Cumulative Explained Variance Ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc315cd8",
   "metadata": {},
   "source": [
    "# check every prefer job accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cafa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abroad</th>\n",
       "      <th>BCS</th>\n",
       "      <th>Bank Job</th>\n",
       "      <th>Business</th>\n",
       "      <th>Cyber Security</th>\n",
       "      <th>Data Analysis</th>\n",
       "      <th>Database Administration</th>\n",
       "      <th>Gaming</th>\n",
       "      <th>Govt Job</th>\n",
       "      <th>Hardware Sector</th>\n",
       "      <th>ML/AI Engineer</th>\n",
       "      <th>Management</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Other</th>\n",
       "      <th>Researcher</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Teaching</th>\n",
       "      <th>UI/UX Designing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>10.59%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.71%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.71%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14.12%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>54.12%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>17.65%</td>\n",
       "      <td>21.18%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>12.94%</td>\n",
       "      <td>20.00%</td>\n",
       "      <td>12.94%</td>\n",
       "      <td>2.35%</td>\n",
       "      <td>22.35%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>17.65%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>16.47%</td>\n",
       "      <td>15.29%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>48.24%</td>\n",
       "      <td>21.18%</td>\n",
       "      <td>5.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>14.12%</td>\n",
       "      <td>4.71%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>2.35%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>12.94%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>51.76%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>16.47%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>4.71%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>15.29%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>15.29%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>47.06%</td>\n",
       "      <td>14.12%</td>\n",
       "      <td>3.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>14.12%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>3.53%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>12.94%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>48.24%</td>\n",
       "      <td>10.59%</td>\n",
       "      <td>3.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard Voting Classifier</th>\n",
       "      <td>14.12%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>12.94%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>51.76%</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting Classifier</th>\n",
       "      <td>16.47%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>9.41%</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14.12%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>12.94%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>7.06%</td>\n",
       "      <td>50.59%</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>1.18%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Abroad     BCS Bank Job Business Cyber Security  \\\n",
       "Logistic Regression     10.59%   5.88%    5.88%    0.00%          4.71%   \n",
       "Decision Tree           17.65%  21.18%   11.76%    9.41%         12.94%   \n",
       "Random Forest           14.12%   4.71%    7.06%    1.18%          5.88%   \n",
       "XGBoost Classifier      16.47%   8.24%   11.76%    3.53%          9.41%   \n",
       "Gradient Boosting       14.12%   8.24%   11.76%    1.18%          9.41%   \n",
       "Hard Voting Classifier  14.12%   5.88%    7.06%    1.18%          7.06%   \n",
       "Soft Voting Classifier  16.47%   9.41%    7.06%    1.18%          9.41%   \n",
       "\n",
       "                       Data Analysis Database Administration Gaming Govt Job  \\\n",
       "Logistic Regression            9.41%                   1.18%  0.00%    4.71%   \n",
       "Decision Tree                 20.00%                  12.94%  2.35%   22.35%   \n",
       "Random Forest                  5.88%                   2.35%  0.00%    8.24%   \n",
       "XGBoost Classifier            11.76%                   4.71%  0.00%   15.29%   \n",
       "Gradient Boosting              8.24%                   3.53%  0.00%    7.06%   \n",
       "Hard Voting Classifier         8.24%                   1.18%  0.00%    9.41%   \n",
       "Soft Voting Classifier         9.41%                   5.88%  0.00%   14.12%   \n",
       "\n",
       "                       Hardware Sector ML/AI Engineer Management Networking  \\\n",
       "Logistic Regression              0.00%         14.12%      0.00%      5.88%   \n",
       "Decision Tree                    3.53%         17.65%      3.53%     16.47%   \n",
       "Random Forest                    0.00%         12.94%      1.18%      3.53%   \n",
       "XGBoost Classifier               0.00%         15.29%      3.53%      5.88%   \n",
       "Gradient Boosting                1.18%         12.94%      1.18%      8.24%   \n",
       "Hard Voting Classifier           0.00%         12.94%      1.18%      8.24%   \n",
       "Soft Voting Classifier           0.00%         12.94%      1.18%     11.76%   \n",
       "\n",
       "                         Other Researcher Software Development Teaching  \\\n",
       "Logistic Regression      3.53%      5.88%               54.12%    3.53%   \n",
       "Decision Tree           15.29%     11.76%               48.24%   21.18%   \n",
       "Random Forest            7.06%      7.06%               51.76%    8.24%   \n",
       "XGBoost Classifier       7.06%      7.06%               47.06%   14.12%   \n",
       "Gradient Boosting        7.06%      9.41%               48.24%   10.59%   \n",
       "Hard Voting Classifier   7.06%      7.06%               51.76%    8.24%   \n",
       "Soft Voting Classifier   7.06%      7.06%               50.59%   11.76%   \n",
       "\n",
       "                       UI/UX Designing  \n",
       "Logistic Regression              0.00%  \n",
       "Decision Tree                    5.88%  \n",
       "Random Forest                    0.00%  \n",
       "XGBoost Classifier               3.53%  \n",
       "Gradient Boosting                3.53%  \n",
       "Hard Voting Classifier           0.00%  \n",
       "Soft Voting Classifier           1.18%  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']), columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']), columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  \n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "# prediction start\n",
    "#df\n",
    "\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)\n",
    "y = prefer_job_encoded\n",
    "\n",
    "\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the features (excluding categorical columns)\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = OneVsRestClassifier(LogisticRegression(max_iter=10000, random_state=42))\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dt = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = MultiOutputClassifier(RandomForestClassifier(random_state=42))\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = OneVsRestClassifier(GradientBoostingClassifier(random_state=42))\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = OneVsRestClassifier(xgb.XGBClassifier(random_state=42))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Hard Voting Classifier\n",
    "hard_voting = MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "], voting='hard'))\n",
    "hard_voting.fit(X_train, y_train)\n",
    "y_pred_hv = hard_voting.predict(X_test)\n",
    "\n",
    "# Soft Voting Classifier\n",
    "soft_voting = MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "], voting='soft'))\n",
    "soft_voting.fit(X_train, y_train)\n",
    "y_pred_sv = soft_voting.predict(X_test)\n",
    "\n",
    "# Function to create a DataFrame with algorithms as rows and job categories as columns\n",
    "def predictions_to_dataframe(y_preds, model_names, job_categories):\n",
    "    predictions_dict = {}\n",
    "    for y_pred, model_name in zip(y_preds, model_names):\n",
    "        model_predictions = []\n",
    "        for category in job_categories:\n",
    "            prediction_percentage = (y_pred[:, mlb_prefer_job.classes_ == category].sum() / len(y_pred)) * 100\n",
    "            model_predictions.append(f\"{prediction_percentage:.2f}%\")\n",
    "        predictions_dict[model_name] = model_predictions\n",
    "    predictions_df = pd.DataFrame(predictions_dict, index=job_categories)\n",
    "    return predictions_df\n",
    "\n",
    "# Get job categories from MultiLabelBinarizer\n",
    "job_categories = mlb_prefer_job.classes_\n",
    "\n",
    "# Collect predictions and model names\n",
    "y_preds = [y_pred_lr,y_pred_dt, y_pred_rf, y_pred_xgb, y_pred_gb,  y_pred_hv, y_pred_sv]\n",
    "model_names = [\"Logistic Regression\",\"Decision Tree\", \"Random Forest\", \"XGBoost Classifier\", \"Gradient Boosting\", \n",
    "                \"Hard Voting Classifier\", \"Soft Voting Classifier\"]\n",
    "\n",
    "\n",
    "predictions_df = predictions_to_dataframe(y_preds, model_names, job_categories)\n",
    "\n",
    "\n",
    "predictions_df = predictions_df.T\n",
    "\n",
    "\n",
    "\n",
    "predictions_df.to_csv('predictions.csv')\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4e109",
   "metadata": {},
   "source": [
    "# check Accuracy & Hamming Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536c9f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "Accuracy: 15.29%\n",
      "Hamming Loss: 0.10915032679738562\n",
      "F1 Score (micro): 0.44518272425249167\n",
      "F1 Score (macro): 0.28386243386243387\n",
      "\n",
      "\n",
      "Results for Decision Tree:\n",
      "Accuracy: 30.59%\n",
      "Hamming Loss: 0.11764705882352941\n",
      "F1 Score (micro): 0.5754716981132075\n",
      "F1 Score (macro): 0.4766659241989286\n",
      "\n",
      "\n",
      "Results for Random Forest:\n",
      "Accuracy: 44.71%\n",
      "Hamming Loss: 0.06601307189542484\n",
      "F1 Score (micro): 0.6752411575562701\n",
      "F1 Score (macro): 0.5099421520219001\n",
      "\n",
      "\n",
      "Results for Gradient Boosting:\n",
      "Accuracy: 34.12%\n",
      "Hamming Loss: 0.0784313725490196\n",
      "F1 Score (micro): 0.6385542168674699\n",
      "F1 Score (macro): 0.5175257748928247\n",
      "\n",
      "\n",
      "Results for XGBoost Classifier:\n",
      "Accuracy: 41.18%\n",
      "Hamming Loss: 0.06928104575163399\n",
      "F1 Score (micro): 0.6954022988505747\n",
      "F1 Score (macro): 0.5938438104316196\n",
      "\n",
      "\n",
      "Results for Hard Voting Classifier:\n",
      "Accuracy: 41.18%\n",
      "Hamming Loss: 0.07254901960784314\n",
      "F1 Score (micro): 0.6520376175548589\n",
      "F1 Score (macro): 0.49834664040835297\n",
      "\n",
      "\n",
      "Results for Soft Voting Classifier:\n",
      "Accuracy: 42.35%\n",
      "Hamming Loss: 0.07647058823529412\n",
      "F1 Score (micro): 0.656891495601173\n",
      "F1 Score (macro): 0.5307941906175555\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"F1 Score (micro):\", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluate each model\n",
    "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "evaluate_model(y_test, y_pred_gb, \"Gradient Boosting\")\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost Classifier\")\n",
    "evaluate_model(y_test, y_pred_hv, \"Hard Voting Classifier\")\n",
    "evaluate_model(y_test, y_pred_sv, \"Soft Voting Classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c465c4d",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb3ecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data shape : (425, 25)\n",
      "training data shape :  (340, 25)\n",
      "test data shape :  (85, 25)\n",
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Abroad: 98.26%\n",
      "Researcher: 23.26%\n",
      "Software Development: 22.06%\n",
      "Teaching: 21.19%\n",
      "Cyber Security: 7.70%\n",
      "Data Analysis: 6.98%\n",
      "UI/UX Designing: 1.55%\n",
      "Database Administration: 1.00%\n",
      "Gaming: 0.51%\n",
      "ML/AI Engineer: 0.43%\n",
      "Business: 0.26%\n",
      "Govt Job: 0.25%\n",
      "Management: 0.19%\n",
      "Other: 0.17%\n",
      "Networking: 0.11%\n",
      "Bank Job: 0.08%\n",
      "BCS: 0.08%\n",
      "Hardware Sector: 0.01%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string \n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job'] \n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"full data shape :\",X.shape)\n",
    "print(\"training data shape : \",X_train.shape)\n",
    "print(\"test data shape : \",X_test.shape)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = OneVsRestClassifier(xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained XGBoost model\n",
    "    y_pred_prob = xgb_model.predict_proba(input_df)\n",
    "\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.9,\n",
    "    'Critical Thinking': 2,\n",
    "    'Problem Solving': 0,\n",
    "    'Team Work': 0,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 1,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 2,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 0,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1, \n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 3,\n",
    "    'publication': 5,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581db2e9",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d4aebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Abroad: 94.34%\n",
      "Data Analysis: 54.28%\n",
      "Researcher: 47.31%\n",
      "Govt Job: 19.05%\n",
      "Teaching: 14.96%\n",
      "Bank Job: 13.46%\n",
      "Software Development: 11.53%\n",
      "Database Administration: 9.97%\n",
      "Business: 8.60%\n",
      "BCS: 8.02%\n",
      "Management: 6.42%\n",
      "UI/UX Designing: 5.83%\n",
      "Networking: 5.46%\n",
      "ML/AI Engineer: 5.19%\n",
      "Other: 3.90%\n",
      "Cyber Security: 3.15%\n",
      "Hardware Sector: 0.25%\n",
      "Gaming: 0.09%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Assuming you have already read and processed your data similar to previous examples\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "svm_model = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=42))\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained SVM model\n",
    "    y_pred_prob = svm_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.9,\n",
    "    'Critical Thinking': 2,\n",
    "    'Problem Solving': 0,\n",
    "    'Team Work': 0,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 1,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 2,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 0,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1, \n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 3,\n",
    "    'publication': 5,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1571d4",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41377220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Abroad: 55.00%\n",
      "Data Analysis: 38.00%\n",
      "Researcher: 36.00%\n",
      "Teaching: 36.00%\n",
      "ML/AI Engineer: 32.00%\n",
      "Software Development: 23.00%\n",
      "Govt Job: 19.00%\n",
      "Other: 19.00%\n",
      "Cyber Security: 18.00%\n",
      "Bank Job: 14.00%\n",
      "Database Administration: 13.00%\n",
      "BCS: 11.00%\n",
      "Management: 9.00%\n",
      "Networking: 8.00%\n",
      "UI/UX Designing: 8.00%\n",
      "Business: 4.00%\n",
      "Gaming: 3.00%\n",
      "Hardware Sector: 1.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already read and processed your data similar to previous examples\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string if necessary (already done in your case)\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RandomForest Classifier\n",
    "rfc_model = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_, index=input_df.index)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained RandomForest model\n",
    "    y_pred_prob = rfc_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.9,\n",
    "    'Critical Thinking': 2,\n",
    "    'Problem Solving': 0,\n",
    "    'Team Work': 0,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 1,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 2,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 0,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1, \n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 3,\n",
    "    'publication': 5,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83eb2b",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652e71f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Software Development: 100.00%\n",
      "ML/AI Engineer: 24.32%\n",
      "Database Administration: 1.53%\n",
      "Data Analysis: 0.71%\n",
      "Cyber Security: 0.62%\n",
      "Other: 0.50%\n",
      "Management: 0.23%\n",
      "Business: 0.05%\n",
      "Abroad: 0.01%\n",
      "Teaching: 0.00%\n",
      "UI/UX Designing: 0.00%\n",
      "Gaming: 0.00%\n",
      "Hardware Sector: 0.00%\n",
      "Researcher: 0.00%\n",
      "Govt Job: 0.00%\n",
      "Bank Job: 0.00%\n",
      "Networking: 0.00%\n",
      "BCS: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Assuming you have already read and processed your data similar to previous examples\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string if necessary (already done in your case)\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_model = OneVsRestClassifier(MLPClassifier(random_state=42, max_iter=1000))\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_, index=input_df.index)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained MLP model\n",
    "    y_pred_prob = mlp_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.7,\n",
    "    'Critical Thinking': 1,\n",
    "    'Problem Solving': 3,\n",
    "    'Team Work': 3,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 3,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 3,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 2,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1,  # Check spelling against X_train columns\n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 0,\n",
    "    'publication': 0,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c335b",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5271fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Abroad  BCS  Bank Job  Business  Cyber Security  Data Analysis  \\\n",
      "0         0    0         0         0               0              0   \n",
      "1         0    0         0         0               0              0   \n",
      "2         0    0         0         0               0              0   \n",
      "3         0    0         0         0               0              0   \n",
      "4         0    0         0         0               0              0   \n",
      "..      ...  ...       ...       ...             ...            ...   \n",
      "420       0    1         1         0               0              0   \n",
      "421       0    0         0         0               0              0   \n",
      "422       0    0         0         0               1              0   \n",
      "423       0    0         0         0               0              1   \n",
      "424       1    0         0         0               0              0   \n",
      "\n",
      "     Database Administration  Gaming  Govt Job  Hardware Sector  \\\n",
      "0                          0       0         0                0   \n",
      "1                          0       0         0                0   \n",
      "2                          0       0         0                0   \n",
      "3                          0       0         0                0   \n",
      "4                          0       0         0                0   \n",
      "..                       ...     ...       ...              ...   \n",
      "420                        0       0         1                0   \n",
      "421                        0       0         0                0   \n",
      "422                        0       0         0                0   \n",
      "423                        0       0         0                0   \n",
      "424                        0       0         0                0   \n",
      "\n",
      "     ML/AI Engineer  Management  Networking  Other  Researcher  \\\n",
      "0                 0           0           0      0           0   \n",
      "1                 0           0           0      0           0   \n",
      "2                 0           0           0      0           0   \n",
      "3                 0           0           0      0           0   \n",
      "4                 0           0           0      0           0   \n",
      "..              ...         ...         ...    ...         ...   \n",
      "420               0           0           0      0           0   \n",
      "421               0           0           0      0           0   \n",
      "422               0           0           1      0           0   \n",
      "423               1           0           0      0           0   \n",
      "424               0           0           0      0           1   \n",
      "\n",
      "     Software Development  Teaching  UI/UX Designing  \n",
      "0                       1         0                0  \n",
      "1                       0         1                0  \n",
      "2                       1         0                0  \n",
      "3                       1         0                0  \n",
      "4                       1         0                0  \n",
      "..                    ...       ...              ...  \n",
      "420                     0         0                0  \n",
      "421                     1         0                0  \n",
      "422                     0         0                0  \n",
      "423                     0         0                0  \n",
      "424                     0         0                0  \n",
      "\n",
      "[425 rows x 18 columns]\n",
      "Predicted Prefer Job Categories with Probabilities (Descending Order):\n",
      "Software Development: 96.25%\n",
      "ML/AI Engineer: 59.73%\n",
      "Data Analysis: 43.58%\n",
      "Database Administration: 25.43%\n",
      "Abroad: 16.98%\n",
      "Other: 7.24%\n",
      "Business: 5.25%\n",
      "Researcher: 2.77%\n",
      "Teaching: 2.48%\n",
      "Cyber Security: 1.52%\n",
      "Govt Job: 1.24%\n",
      "Management: 0.76%\n",
      "Networking: 0.66%\n",
      "Bank Job: 0.27%\n",
      "BCS: 0.24%\n",
      "UI/UX Designing: 0.17%\n",
      "Gaming: 0.00%\n",
      "Hardware Sector: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Convert columns to string if necessary (already done in your case)\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str)\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str)\n",
    "\n",
    "# Split 'Influencing Factor' and 'Prefer Job' into lists\n",
    "df['Influencing Factor'] = df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Prefer Job'] = df['Prefer Job'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']),\n",
    "                                           columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']),\n",
    "                                  columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "print(prefer_job_encoded)\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)  # Features\n",
    "y = prefer_job_encoded  # Labels\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression with OneVsRestClassifier\n",
    "lr_model = OneVsRestClassifier(LogisticRegression(max_iter=1000))  # Increase max_iter if necessary\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Define a function to predict job probabilities based on input data\n",
    "def predict_job_probabilities(input_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Process 'Influencing Factor' for encoding\n",
    "    input_df['Influencing Factor'] = input_df['Influencing Factor'].apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "    influencing_factors_encoded_input = pd.DataFrame(mlb_influencing.transform(input_df['Influencing Factor']),\n",
    "                                                    columns=mlb_influencing.classes_, index=input_df.index)\n",
    "\n",
    "    # Drop 'Influencing Factor' after encoding\n",
    "    input_df = input_df.drop(['Influencing Factor'], axis=1)\n",
    "\n",
    "    # Concatenate encoded features with input DataFrame\n",
    "    input_df = pd.concat([input_df, influencing_factors_encoded_input], axis=1)\n",
    "\n",
    "    # Standardize numerical columns in input data\n",
    "    input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "    # Predict probabilities using the trained Logistic Regression model\n",
    "    y_pred_prob = lr_model.predict_proba(input_df)\n",
    "\n",
    "    # Extracting only the 'Prefer Job' categories probabilities\n",
    "    predicted_probabilities = {}\n",
    "    for idx, job_category in enumerate(mlb_prefer_job.classes_):\n",
    "        predicted_probabilities[job_category] = y_pred_prob[0][idx] * 100  # Convert probability to percentage\n",
    "\n",
    "    return predicted_probabilities\n",
    "\n",
    "# Example input data for prediction (excluding 'Machine Learning' skill)\n",
    "input_data = {\n",
    "    'cgpa': 3.7,\n",
    "    'Critical Thinking': 1,\n",
    "    'Problem Solving': 2,\n",
    "    'Team Work': 3,\n",
    "    'Communication Skill': 2,\n",
    "    'Software Engineering Principal': 2,\n",
    "    'Data Structure & Algorithm': 2,\n",
    "    'Database Management': 3,\n",
    "    'Data Analysis skill': 2,\n",
    "    'Web Developing Skill': 2,\n",
    "    'Understanding of computer architecture & System': 0,\n",
    "    'Understanding Operating System': 0,\n",
    "    'Networking Concept': 1,\n",
    "    'Cyber Security Skill': 1,\n",
    "    'Machine Learning Skill': 1,  # Check spelling against X_train columns\n",
    "    'Robotics Skill': 0,\n",
    "    'Research Skill': 0,\n",
    "    'publication': 0,\n",
    "    'project': 3,\n",
    "    'Influencing Factor': 'Salary, Job Environment'\n",
    "}\n",
    "\n",
    "# Predict job categories based on input data\n",
    "predicted_probabilities = predict_job_probabilities(input_data)\n",
    "\n",
    "# Sort predicted probabilities in descending order\n",
    "sorted_probabilities = sorted(predicted_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Predicted Prefer Job Categories with Probabilities (Descending Order):\")\n",
    "for job_category, percentage in sorted_probabilities:\n",
    "    print(f\"{job_category}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4970ab",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "\n",
    "*Evaluate the models using metrics such as accuracy, precision, recall, F1-score, and ROC-AUC.\n",
    "\n",
    "\n",
    "\n",
    "*Use cross-validation to ensure the model's robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4204d223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Logistic Regression:\n",
      "Accuracy: 0.14\n",
      "Precision: 0.41\n",
      "Recall: 0.21\n",
      "\n",
      "\n",
      "Evaluating Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Decision Tree:\n",
      "Accuracy: 0.33\n",
      "Precision: 0.48\n",
      "Recall: 0.52\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Random Forest:\n",
      "Accuracy: 0.43\n",
      "Precision: 0.67\n",
      "Recall: 0.44\n",
      "\n",
      "\n",
      "Evaluating Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Gradient Boosting:\n",
      "Accuracy: 0.33\n",
      "Precision: 0.62\n",
      "Recall: 0.44\n",
      "\n",
      "\n",
      "Evaluating XGBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 634, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 118, in _average_binary_score\n",
      "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 381, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for XGBoost Classifier:\n",
      "Accuracy: 0.40\n",
      "Precision: 0.64\n",
      "Recall: 0.50\n",
      "\n",
      "\n",
      "Evaluating Hard Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 399, in _score\n",
      "    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=self._get_pos_label())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 73, in _get_response_values\n",
      "    prediction_method = _check_response_method(estimator, response_method)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1940, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: MultiOutputClassifier has none of the following attributes: predict_proba.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Hard Voting Classifier:\n",
      "Accuracy: 0.41\n",
      "Precision: 0.68\n",
      "Recall: 0.44\n",
      "\n",
      "\n",
      "Evaluating Soft Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 401, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 953, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with dim 3. None expected <= 2.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for Soft Voting Classifier:\n",
      "Accuracy: 0.39\n",
      "Precision: 0.65\n",
      "Recall: 0.47\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "\n",
    "# Drop original 'Influencing Factor' and 'Prefer Job', and concatenate encoded columns\n",
    "columns_to_drop = ['Unnamed: 0','year','gender','university_name']  # Drop original columns after encoding\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "# Convert 'Prefer Job' and 'Influencing Factor' columns to string and split into lists\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']), columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']), columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original columns and combine encoded features with the dataframe\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)\n",
    "y = prefer_job_encoded\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the features (excluding categorical columns)\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Splitting into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': OneVsRestClassifier(LogisticRegression(max_iter=10000, random_state=42)),\n",
    "    'Decision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=42)),\n",
    "    'Random Forest': MultiOutputClassifier(RandomForestClassifier(random_state=42)),\n",
    "    'Gradient Boosting': OneVsRestClassifier(GradientBoostingClassifier(random_state=42)),\n",
    "    'XGBoost Classifier': OneVsRestClassifier(xgb.XGBClassifier(random_state=42)),\n",
    "    'Hard Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='hard')),\n",
    "    'Soft Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='soft'))\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']\n",
    "\n",
    "# Perform cross-validation and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Extract and print evaluation metrics\n",
    "    accuracy = cv_results['test_accuracy'].mean()\n",
    "    precision = cv_results['test_precision_macro'].mean()\n",
    "    recall = cv_results['test_recall_macro'].mean()\n",
    "    #f1 = cv_results['test_f1_macro'].mean()\n",
    "   # roc_auc = cv_results['test_roc_auc_ovr'].mean()\n",
    "    \n",
    "    print(f\"Cross-validation results for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    #print(f\"F1-score: {f1:.2f}\")\n",
    "   # print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb87f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\jupyter_work\\\\rrr_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load your CSV file\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mjupyter_work\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrrr_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert 'Prefer Job' and 'Influencing Factor' columns to string and split into lists\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrefer Job\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrefer Job\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [cat\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\jupyter_work\\\\rrr_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"C:\\\\jupyter_work\\\\rrr_data.csv\")\n",
    "\n",
    "# Convert 'Prefer Job' and 'Influencing Factor' columns to string and split into lists\n",
    "df['Prefer Job'] = df['Prefer Job'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "df['Influencing Factor'] = df['Influencing Factor'].astype(str).apply(lambda x: [cat.strip() for cat in x.split(',')])\n",
    "\n",
    "# Using MultiLabelBinarizer for 'Influencing Factor' and 'Prefer Job'\n",
    "mlb_influencing = MultiLabelBinarizer()\n",
    "influencing_factors_encoded = pd.DataFrame(mlb_influencing.fit_transform(df['Influencing Factor']), columns=mlb_influencing.classes_, index=df.index)\n",
    "\n",
    "mlb_prefer_job = MultiLabelBinarizer()\n",
    "prefer_job_encoded = pd.DataFrame(mlb_prefer_job.fit_transform(df['Prefer Job']), columns=mlb_prefer_job.classes_, index=df.index)\n",
    "\n",
    "# Drop original columns and combine encoded features with the dataframe\n",
    "columns_to_drop = ['Influencing Factor', 'Prefer Job']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df = pd.concat([df, influencing_factors_encoded, prefer_job_encoded], axis=1)\n",
    "\n",
    "# Splitting the data into features and labels\n",
    "X = df.drop(prefer_job_encoded.columns, axis=1)\n",
    "y = prefer_job_encoded\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Standardize the features (excluding categorical columns)\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "# Splitting into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': OneVsRestClassifier(LogisticRegression(max_iter=10000, random_state=42)),\n",
    "    'Decision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=42)),\n",
    "    'Random Forest': MultiOutputClassifier(RandomForestClassifier(random_state=42)),\n",
    "    'Gradient Boosting': OneVsRestClassifier(GradientBoostingClassifier(random_state=42)),\n",
    "    'XGBoost Classifier': OneVsRestClassifier(xgb.XGBClassifier(random_state=42)),\n",
    "    'Hard Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='hard')),\n",
    "    'Soft Voting Classifier': MultiOutputClassifier(VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=10000, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "    ], voting='soft'))\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']\n",
    "\n",
    "# Perform cross-validation and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Extract and print evaluation metrics\n",
    "    accuracy = cv_results['test_accuracy'].mean()\n",
    "    precision = cv_results['test_precision_macro'].mean()\n",
    "    recall = cv_results['test_recall_macro'].mean()\n",
    "    f1 = cv_results['test_f1_macro'].mean()\n",
    "    roc_auc = cv_results['test_roc_auc_ovr'].mean()\n",
    "    \n",
    "    print(f\"Cross-validation results for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715c30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e701cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Update softmax prediction logic for multi-label classification\n",
    "def predict_with_threshold(model, X_test, threshold=0.5):\n",
    "    # Get the probability distribution (predict_proba) for models that support it\n",
    "    proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Convert probabilities into binary predictions based on the threshold\n",
    "    # proba is a list of arrays, so we iterate over it and apply the threshold\n",
    "    return np.array([np.where(p >= threshold, 1, 0) for p in proba]).T\n",
    "\n",
    "# Evaluate models using thresholded predictions for multi-label classification\n",
    "def evaluate_model_thresholded(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"F1 Score (micro):\", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Apply the new threshold-based prediction and evaluation for each model\n",
    "y_pred_lr_threshold = predict_with_threshold(lr, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_lr_threshold, \"Logistic Regression\")\n",
    "\n",
    "y_pred_rf_threshold = predict_with_threshold(rf, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_rf_threshold, \"Random Forest\")\n",
    "\n",
    "y_pred_gb_threshold = predict_with_threshold(gb, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_gb_threshold, \"Gradient Boosting\")\n",
    "\n",
    "y_pred_xgb_threshold = predict_with_threshold(xgb_model, X_test)\n",
    "evaluate_model_thresholded(y_test, y_pred_xgb_threshold, \"XGBoost Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bd0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f96bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
